{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook that can be uploaded to Kaggle and run to generate the submission file for the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T11:40:41.983404Z",
     "iopub.status.busy": "2025-03-20T11:40:41.983169Z",
     "iopub.status.idle": "2025-03-20T11:40:41.992328Z",
     "shell.execute_reply": "2025-03-20T11:40:41.991750Z",
     "shell.execute_reply.started": "2025-03-20T11:40:41.983372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T11:40:41.993582Z",
     "iopub.status.busy": "2025-03-20T11:40:41.993316Z",
     "iopub.status.idle": "2025-03-20T11:40:42.030626Z",
     "shell.execute_reply": "2025-03-20T11:40:42.030032Z",
     "shell.execute_reply.started": "2025-03-20T11:40:41.993557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CONFIG = dict(\n",
    "    seed = 42,\n",
    "    model_name = '../input/bert-base-uncased',\n",
    "    test_batch_size = 64,\n",
    "    max_length = 256,\n",
    "    num_classes = 1,\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T11:40:42.031849Z",
     "iopub.status.busy": "2025-03-20T11:40:42.031646Z",
     "iopub.status.idle": "2025-03-20T11:40:42.035288Z",
     "shell.execute_reply": "2025-03-20T11:40:42.034473Z",
     "shell.execute_reply.started": "2025-03-20T11:40:42.031822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATHS = [\n",
    "    '../input/bert-fold-4/model_fold_0.pth',\n",
    "    '../input/bert-fold-4/model_fold_1.pth',\n",
    "    '../input/bert-fold-4/model_fold_2.pth',\n",
    "    '../input/bert-fold-4/model_fold_3.pth',\n",
    "    '../input/bert-fold-4/model_fold_4.pth',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T11:40:42.037387Z",
     "iopub.status.busy": "2025-03-20T11:40:42.037185Z",
     "iopub.status.idle": "2025-03-20T11:40:42.045922Z",
     "shell.execute_reply": "2025-03-20T11:40:42.045127Z",
     "shell.execute_reply.started": "2025-03-20T11:40:42.037357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T11:40:42.047057Z",
     "iopub.status.busy": "2025-03-20T11:40:42.046821Z",
     "iopub.status.idle": "2025-03-20T11:40:42.108201Z",
     "shell.execute_reply": "2025-03-20T11:40:42.107564Z",
     "shell.execute_reply.started": "2025-03-20T11:40:42.047020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1      732895  Looks like be have an abuser , can you please ...\n",
       "2     1139051  I confess to having complete (and apparently b...\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4     2084821  It is not just you. This is a laundry list of ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T11:40:42.109563Z",
     "iopub.status.busy": "2025-03-20T11:40:42.109300Z",
     "iopub.status.idle": "2025-03-20T11:40:42.115214Z",
     "shell.execute_reply": "2025-03-20T11:40:42.114569Z",
     "shell.execute_reply.started": "2025-03-20T11:40:42.109536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df['text'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len,\n",
    "                        padding='max_length'\n",
    "                    )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']        \n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T11:40:42.116780Z",
     "iopub.status.busy": "2025-03-20T11:40:42.116393Z",
     "iopub.status.idle": "2025-03-20T11:40:42.130345Z",
     "shell.execute_reply": "2025-03-20T11:40:42.129712Z",
     "shell.execute_reply.started": "2025-03-20T11:40:42.116742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n",
    "                         shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:25:27.851919Z",
     "iopub.status.busy": "2025-03-20T12:25:27.851458Z",
     "iopub.status.idle": "2025-03-20T12:25:27.857074Z",
     "shell.execute_reply": "2025-03-20T12:25:27.856476Z",
     "shell.execute_reply.started": "2025-03-20T12:25:27.851879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class JigsawModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(JigsawModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name, return_dict=False)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        _, out = self.model(input_ids=ids,attention_mask=mask)\n",
    "        out = self.drop(out)\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:25:28.077778Z",
     "iopub.status.busy": "2025-03-20T12:25:28.077557Z",
     "iopub.status.idle": "2025-03-20T12:25:28.083362Z",
     "shell.execute_reply": "2025-03-20T12:25:28.082620Z",
     "shell.execute_reply.started": "2025-03-20T12:25:28.077755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    PREDS = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        \n",
    "        outputs = model(ids, mask)\n",
    "        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n",
    "    \n",
    "    PREDS = np.concatenate(PREDS)\n",
    "    gc.collect()\n",
    "    \n",
    "    return PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:25:44.273433Z",
     "iopub.status.busy": "2025-03-20T12:25:44.273187Z",
     "iopub.status.idle": "2025-03-20T12:25:44.278885Z",
     "shell.execute_reply": "2025-03-20T12:25:44.278059Z",
     "shell.execute_reply.started": "2025-03-20T12:25:44.273393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inference(model_paths, dataloader, device):\n",
    "    final_preds = []\n",
    "    for i, path in enumerate(model_paths):\n",
    "        model = JigsawModel(CONFIG['model_name'])\n",
    "        model.to(CONFIG['device'])\n",
    "        model.load_state_dict(torch.load(path),strict=False)\n",
    "        \n",
    "        print(f\"Getting predictions for model {i+1}\")\n",
    "        preds = valid_fn(model, dataloader, device)\n",
    "        final_preds.append(preds)\n",
    "    \n",
    "    final_preds = np.array(final_preds)\n",
    "    final_preds = np.mean(final_preds, axis=0)\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:25:44.448851Z",
     "iopub.status.busy": "2025-03-20T12:25:44.448597Z",
     "iopub.status.idle": "2025-03-20T12:26:49.308952Z",
     "shell.execute_reply": "2025-03-20T12:26:49.308160Z",
     "shell.execute_reply.started": "2025-03-20T12:25:44.448824Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [01:02<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(MODEL_PATHS, test_loader, CONFIG['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:27:14.751850Z",
     "iopub.status.busy": "2025-03-20T12:27:14.751587Z",
     "iopub.status.idle": "2025-03-20T12:27:14.757604Z",
     "shell.execute_reply": "2025-03-20T12:27:14.756882Z",
     "shell.execute_reply.started": "2025-03-20T12:27:14.751817Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3884304 , -0.5081454 , -0.32211098, -0.35622755, -0.10511924],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:27:31.114593Z",
     "iopub.status.busy": "2025-03-20T12:27:31.113812Z",
     "iopub.status.idle": "2025-03-20T12:27:31.118820Z",
     "shell.execute_reply": "2025-03-20T12:27:31.118219Z",
     "shell.execute_reply.started": "2025-03-20T12:27:31.114546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Predictiions: 7537\n",
      "Total Unique Predictions: 7524\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Predictiions: {preds.shape[0]}\")\n",
    "print(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:27:33.546556Z",
     "iopub.status.busy": "2025-03-20T12:27:33.546258Z",
     "iopub.status.idle": "2025-03-20T12:27:33.556426Z",
     "shell.execute_reply": "2025-03-20T12:27:33.555649Z",
     "shell.execute_reply.started": "2025-03-20T12:27:33.546525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "      <td>-0.388430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "      <td>-0.508145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "      <td>-0.322111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "      <td>-0.356228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "      <td>-0.105119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text     score\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther... -0.388430\n",
       "1      732895  Looks like be have an abuser , can you please ... -0.508145\n",
       "2     1139051  I confess to having complete (and apparently b... -0.322111\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse... -0.356228\n",
       "4     2084821  It is not just you. This is a laundry list of ... -0.105119"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'] = preds\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:27:56.994765Z",
     "iopub.status.busy": "2025-03-20T12:27:56.994075Z",
     "iopub.status.idle": "2025-03-20T12:27:57.008958Z",
     "shell.execute_reply": "2025-03-20T12:27:57.008213Z",
     "shell.execute_reply.started": "2025-03-20T12:27:56.994731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "      <td>1084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "      <td>1874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "      <td>1428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "      <td>4657.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text   score\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...  1084.0\n",
       "1      732895  Looks like be have an abuser , can you please ...   225.0\n",
       "2     1139051  I confess to having complete (and apparently b...  1874.0\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...  1428.0\n",
       "4     2084821  It is not just you. This is a laundry list of ...  4657.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'] = df['score'].rank(method='first')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:29:00.086963Z",
     "iopub.status.busy": "2025-03-20T12:29:00.086451Z",
     "iopub.status.idle": "2025-03-20T12:29:00.109069Z",
     "shell.execute_reply": "2025-03-20T12:29:00.108528Z",
     "shell.execute_reply.started": "2025-03-20T12:29:00.086931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.drop('text', axis=1, inplace=True)\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 3445671,
     "isSourceIdPinned": false,
     "sourceId": 27935,
     "sourceType": "competition"
    },
    {
     "datasetId": 6921007,
     "sourceId": 11102223,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6921417,
     "sourceId": 11102951,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30146,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
